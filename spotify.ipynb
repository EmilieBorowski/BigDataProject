{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pycountry\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\reyse\\documents\\github\\bigdata-assigment\\bigdata-assignment\\bigdataproject\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\reyse\\documents\\github\\bigdata-assigment\\bigdata-assignment\\bigdataproject\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached numpy-2.2.3-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pycountry, numpy, pandas\n",
      "Successfully installed numpy-2.2.3 pandas-2.2.3 pycountry-24.6.1 pytz-2025.1 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load datasets: 7.21 seconds\n",
      "Time to convert country codes: 1.82 seconds\n",
      "Time to calculate average tempo: 0.11 seconds\n",
      "Time to extract average age: 0.01 seconds\n",
      "Time to merge datasets: 0.02 seconds\n",
      "Time to calculate deviation: 0.01 seconds\n",
      "\n",
      "Total execution time: 9.17 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timing the entire process\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Load datasets\n",
    "load_start = time.time()\n",
    "spotify_df = pd.read_csv(\"universal_top_spotify_songs.csv\")\n",
    "age_df = pd.read_csv(\"MedianAge.csv\")\n",
    "load_end = time.time()\n",
    "print(f\"Time to load datasets: {load_end - load_start:.2f} seconds\")\n",
    "\n",
    "# Step 2: Convert country codes to names using pycountry\n",
    "convert_start = time.time()\n",
    "def code_to_name(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).name\n",
    "    except:\n",
    "        return None  # Handle invalid or missing codes\n",
    "\n",
    "spotify_df[\"country_name\"] = spotify_df[\"country\"].apply(code_to_name)\n",
    "convert_end = time.time()\n",
    "print(f\"Time to convert country codes: {convert_end - convert_start:.2f} seconds\")\n",
    "\n",
    "# Step 3: Calculate average tempo per country\n",
    "tempo_start = time.time()\n",
    "avg_tempo_per_country = spotify_df.groupby(\"country_name\")[\"tempo\"].mean().reset_index()\n",
    "tempo_end = time.time()\n",
    "print(f\"Time to calculate average tempo: {tempo_end - tempo_start:.2f} seconds\")\n",
    "\n",
    "# Step 4: Extract most recent average age (2025)\n",
    "age_start = time.time()\n",
    "age_df[\"average_age\"] = age_df[\"2025\"]\n",
    "age_df = age_df[[\"Country\", \"average_age\"]]\n",
    "age_end = time.time()\n",
    "print(f\"Time to extract average age: {age_end - age_start:.2f} seconds\")\n",
    "\n",
    "# Step 5: Merge datasets\n",
    "merge_start = time.time()\n",
    "merged_df = pd.merge(avg_tempo_per_country, age_df, left_on=\"country_name\", right_on=\"Country\")\n",
    "merge_end = time.time()\n",
    "print(f\"Time to merge datasets: {merge_end - merge_start:.2f} seconds\")\n",
    "\n",
    "# Step 6: Calculate deviation (difference between tempo and age)\n",
    "deviation_start = time.time()\n",
    "merged_df[\"deviation\"] = merged_df[\"tempo\"] - merged_df[\"average_age\"]\n",
    "deviation_end = time.time()\n",
    "print(f\"Time to calculate deviation: {deviation_end - deviation_start:.2f} seconds\")\n",
    "\n",
    "# End timing the entire process (before plots are displayed)\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-9G985THQ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x208cca9c190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) #  This will format our output tables a bit nicer when not using the show() method\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\reyse\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\reyse\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in c:\\users\\reyse\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (24.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- spotify_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- daily_rank: string (nullable = true)\n",
      " |-- daily_movement: string (nullable = true)\n",
      " |-- weekly_movement: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- snapshot_date: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- is_explicit: string (nullable = true)\n",
      " |-- duration_ms: string (nullable = true)\n",
      " |-- album_name: string (nullable = true)\n",
      " |-- album_release_date: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- time_signature: double (nullable = true)\n",
      "\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "|          spotify_id|              name|             artists|daily_rank|daily_movement|weekly_movement|country|snapshot_date|popularity|is_explicit|duration_ms|          album_name|album_release_date|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|time_signature|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "|2plbrEY59IikOBgBG...|  Die With A Smile|Lady Gaga, Bruno ...|         1|             0|              2|     GL|   2025-02-20|        98|      False|     251667|    Die With A Smile|        2024-08-16|       0.521| 0.592|  6|  -7.777|   0|     0.0304|       0.308|             0.0|   0.122|  0.535|157.969|           3.0|\n",
      "|2CGNAOSuO1MEFCbBR...| luther (with sza)| Kendrick Lamar, SZA|         2|             0|              0|     GL|   2025-02-20|        90|      False|     177598|                 GNX|        2024-11-21|       0.707| 0.575|  2|  -7.546|   1|      0.125|       0.251|             0.0|   0.248|  0.576|138.008|           4.0|\n",
      "|6AI3ezQ4o3HUoP6Dh...|       Not Like Us|      Kendrick Lamar|         3|             0|             -2|     GL|   2025-02-20|        93|       True|     274192|         Not Like Us|        2024-05-04|       0.898| 0.472|  1|  -7.001|   1|     0.0776|      0.0107|             0.0|   0.141|  0.214|101.061|           4.0|\n",
      "|4wJ5Qq0jBN4ajy7ou...|              APT.|    ROSÉ, Bruno Mars|         4|             0|              0|     GL|   2025-02-20|        89|      False|     169917|               rosie|        2024-12-06|       0.777| 0.783|  0|  -4.477|   0|       0.26|      0.0283|             0.0|   0.355|  0.939|149.027|           4.0|\n",
      "|6dOtVTDdiauQNBQED...|BIRDS OF A FEATHER|       Billie Eilish|         5|             0|              1|     GL|   2025-02-20|        95|      False|     210373|HIT ME HARD AND SOFT|        2024-05-17|       0.747| 0.507|  2| -10.171|   1|     0.0358|         0.2|          0.0608|   0.117|  0.438|104.978|           4.0|\n",
      "+--------------------+------------------+--------------------+----------+--------------+---------------+-------+-------------+----------+-----------+-----------+--------------------+------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Row(spotify_id='2plbrEY59IikOBgBGLjaoe', name='Die With A Smile', artists='Lady Gaga, Bruno Mars', daily_rank='1', daily_movement='0', weekly_movement='2', country='GL', snapshot_date='2025-02-20', popularity='98', is_explicit='False', duration_ms='251667', album_name='Die With A Smile', album_release_date='2024-08-16', danceability='0.521', energy='0.592', key='6', loudness='-7.777', mode='0', speechiness='0.0304', acousticness=0.308, instrumentalness=0.0, liveness=0.122, valence=0.535, tempo=157.969, time_signature=3.0)\n",
      "Row(spotify_id='2CGNAOSuO1MEFCbBRgUzjd', name='luther (with sza)', artists='Kendrick Lamar, SZA', daily_rank='2', daily_movement='0', weekly_movement='0', country='GL', snapshot_date='2025-02-20', popularity='90', is_explicit='False', duration_ms='177598', album_name='GNX', album_release_date='2024-11-21', danceability='0.707', energy='0.575', key='2', loudness='-7.546', mode='1', speechiness='0.125', acousticness=0.251, instrumentalness=0.0, liveness=0.248, valence=0.576, tempo=138.008, time_signature=4.0)\n",
      "Row(spotify_id='6AI3ezQ4o3HUoP6Dhudph3', name='Not Like Us', artists='Kendrick Lamar', daily_rank='3', daily_movement='0', weekly_movement='-2', country='GL', snapshot_date='2025-02-20', popularity='93', is_explicit='True', duration_ms='274192', album_name='Not Like Us', album_release_date='2024-05-04', danceability='0.898', energy='0.472', key='1', loudness='-7.001', mode='1', speechiness='0.0776', acousticness=0.0107, instrumentalness=0.0, liveness=0.141, valence=0.214, tempo=101.061, time_signature=4.0)\n",
      "Row(spotify_id='4wJ5Qq0jBN4ajy7ouZIV1c', name='APT.', artists='ROSÉ, Bruno Mars', daily_rank='4', daily_movement='0', weekly_movement='0', country='GL', snapshot_date='2025-02-20', popularity='89', is_explicit='False', duration_ms='169917', album_name='rosie', album_release_date='2024-12-06', danceability='0.777', energy='0.783', key='0', loudness='-4.477', mode='0', speechiness='0.26', acousticness=0.0283, instrumentalness=0.0, liveness=0.355, valence=0.939, tempo=149.027, time_signature=4.0)\n",
      "Row(spotify_id='6dOtVTDdiauQNBQEDOtlAB', name='BIRDS OF A FEATHER', artists='Billie Eilish', daily_rank='5', daily_movement='0', weekly_movement='1', country='GL', snapshot_date='2025-02-20', popularity='95', is_explicit='False', duration_ms='210373', album_name='HIT ME HARD AND SOFT', album_release_date='2024-05-17', danceability='0.747', energy='0.507', key='2', loudness='-10.171', mode='1', speechiness='0.0358', acousticness=0.2, instrumentalness=0.0608, liveness=0.117, valence=0.438, tempo=104.978, time_signature=4.0)\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"new_spotify.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Inspect the schema and data\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "\n",
    "# Step 3: Convert DataFrame to RDD and process\n",
    "spotify_rdd = df.rdd\n",
    "\n",
    "# Step 4: Inspect the processed data\n",
    "for row in spotify_rdd.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load datasets: 0.22 seconds\n",
      "Time to convert country codes: 1.01 seconds\n",
      "Time to calculate average tempo: 0.05 seconds\n",
      "Time to extract average age: 0.72 seconds\n",
      "Time to join datasets: 0.03 seconds\n",
      "Time to calculate deviation: 0.00 seconds\n",
      "Time to collect results: 0.00 seconds\n",
      "\n",
      "Total execution time: 2.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "import pycountry\n",
    "\n",
    "# Reuse the existing SparkSession and SparkContext\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext  # Get the existing SparkContext\n",
    "\n",
    "# Start timing the entire process\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Load datasets\n",
    "load_start = time.time()\n",
    "spotify_rdd = sc.textFile(\"new_spotify.csv\")\n",
    "age_rdd = sc.textFile(\"MedianAge.csv\")\n",
    "load_end = time.time()\n",
    "print(f\"Time to load datasets: {load_end - load_start:.2f} seconds\")\n",
    "\n",
    "# Step 2: Convert country codes to names using pycountry\n",
    "convert_start = time.time()\n",
    "def code_to_name(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).name\n",
    "    except:\n",
    "        return None  # Handle invalid or missing codes\n",
    "\n",
    "# Remove header and map Spotify data to (country_code, tempo)\n",
    "header = spotify_rdd.first()\n",
    "spotify_rdd = spotify_rdd.filter(lambda line: line != header).map(lambda line: line.split(\",\"))\n",
    "spotify_rdd = spotify_rdd.map(lambda x: (x[6], float(x[23])))  # (country_code, tempo)\n",
    "\n",
    "# Convert country codes to names\n",
    "spotify_rdd = spotify_rdd.map(lambda x: (code_to_name(x[0]), x[1]))  # (country_name, tempo)\n",
    "\n",
    "# Filter out null values\n",
    "spotify_rdd = spotify_rdd.filter(lambda x: x[0] is not None and x[1] is not None)\n",
    "convert_end = time.time()\n",
    "print(f\"Time to convert country codes: {convert_end - convert_start:.2f} seconds\")\n",
    "\n",
    "# Step 3: Calculate average tempo per country using MapReduce\n",
    "tempo_start = time.time()\n",
    "# Map: Emit (country_name, (tempo, 1)) for each song\n",
    "tempo_mapped = spotify_rdd.map(lambda x: (x[0], (x[1], 1)))\n",
    "\n",
    "# Reduce: Sum tempo and count for each country\n",
    "tempo_reduced = tempo_mapped.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "# Calculate average tempo\n",
    "avg_tempo_rdd = tempo_reduced.mapValues(lambda x: x[0] / x[1])  # (country_name, avg_tempo)\n",
    "tempo_end = time.time()\n",
    "print(f\"Time to calculate average tempo: {tempo_end - tempo_start:.2f} seconds\")\n",
    "\n",
    "# Step 4: Extract most recent average age (2025) using MapReduce\n",
    "age_start = time.time()\n",
    "# Remove header and map age data to (country_name, average_age)\n",
    "header = age_rdd.first()\n",
    "age_rdd = age_rdd.filter(lambda line: line != header).map(lambda line: line.split(\",\"))\n",
    "age_rdd = age_rdd.map(lambda x: (x[0], float(x[-1])))  # (country_name, average_age)\n",
    "\n",
    "# Filter out null values\n",
    "age_rdd = age_rdd.filter(lambda x: x[0] is not None and x[1] is not None)\n",
    "age_end = time.time()\n",
    "print(f\"Time to extract average age: {age_end - age_start:.2f} seconds\")\n",
    "\n",
    "# Step 5: Join datasets using MapReduce\n",
    "join_start = time.time()\n",
    "# Join on country_name\n",
    "joined_rdd = avg_tempo_rdd.join(age_rdd)  # (country_name, (avg_tempo, average_age))\n",
    "join_end = time.time()\n",
    "print(f\"Time to join datasets: {join_end - join_start:.2f} seconds\")\n",
    "\n",
    "# Step 6: Calculate deviation (difference between tempo and age)\n",
    "deviation_start = time.time()\n",
    "# Map: Calculate deviation\n",
    "deviation_rdd = joined_rdd.mapValues(lambda x: x[0] - x[1])  # (country_name, deviation)\n",
    "\n",
    "# Filter out invalid deviations\n",
    "deviation_rdd = deviation_rdd.filter(lambda x: x[1] is not None and not isinstance(x[1], float))\n",
    "deviation_end = time.time()\n",
    "print(f\"Time to calculate deviation: {deviation_end - deviation_start:.2f} seconds\")\n",
    "\n",
    "# Step 7: Collect results and print\n",
    "collect_start = time.time()\n",
    "collect_end = time.time()\n",
    "print(f\"Time to collect results: {collect_end - collect_start:.2f} seconds\")\n",
    "\n",
    "# End timing the entire process\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Stop Spark (optional, as it will be stopped automatically when the session ends)\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
